# TP - Ing√©nierie de Prompt appliqu√©e √† la g√©n√©ration de code avec l‚ÄôIA ü§ñ

##  Encadr√© par :
Prof. Imane Allaouzi
## üéØ Objectif du TP

Ce TP a pour but d'apprendre √† concevoir des **prompts efficaces** pour g√©n√©rer du **code de qualit√© avec une IA g√©n√©rative**, en suivant les principes fondamentaux :
- **T√¢che**
- **Contexte**
- **R√©f√©rences**
- **√âvaluation**
- **It√©ration**

---

## üß† Partie 1 ‚Äì Choix de la solution d'IA g√©n√©rative
# TP - Ing√©nierie de Prompt appliqu√©e √† la g√©n√©ration de code avec l‚ÄôIA ü§ñüíª

## üë©‚Äçüè´ Encadr√© par :
Prof. Imane Allaouzi

---

## üéØ Objectif du TP

Ce TP a pour but d'apprendre √† concevoir des **prompts efficaces** pour g√©n√©rer du **code de qualit√© avec une IA g√©n√©rative**, en suivant les principes fondamentaux :
- **T√¢che**
- **Contexte**
- **R√©f√©rences**
- **√âvaluation**
- **It√©ration**

---

## üß† Partie 1 ‚Äì Choix de la solution d'IA g√©n√©rative

### ‚úÖ Solution choisie : **ChatGPT (OpenAI)**

### üîç D√©finition br√®ve :
ChatGPT est un assistant conversationnel d√©velopp√© par OpenAI, capable de g√©n√©rer, corriger, am√©liorer et expliquer du code √† partir de requ√™tes en langage naturel.

### ‚úîÔ∏è Avantages :
- G√©n√©ration rapide de code multi-langage (Python, JS, HTML, etc.).
- Peut expliquer les erreurs, refactorer et optimiser du code existant.
- R√©pond de mani√®re interactive et personnalis√©e avec contexte.

### ‚ö†Ô∏è Inconv√©nients :
- Peut produire du code incorrect sans pr√©venir.
- Ne comprend pas toujours les besoins implicites.
- Pas d‚Äôacc√®s direct √† l‚Äôenvironnement de test ou de compilation.

### üíº Cas d‚Äôutilisation typiques :
- G√©n√©ration de fonctions ou algorithmes simples ou complexes.
- R√©daction de docstrings et fichiers `README.md`.
- D√©bogage et am√©lioration de code existant.
- Simulation de comportements utilisateur (persona).

## üß† Partie 2 ‚Äì G√©n√©ration de code avec IA
# Exercice 2.1 : G√©n√©ration de code Python pour une t√¢che de calcul :
‚Ä¢Prompt Vague :
->La fonction `calculate(a, b, op)` est clairement nomm√©e de mani√®re pertinente et descriptive. Elle prend en charge les quatre op√©rations math√©matiques de base : addition, soustraction, multiplication et division, avec un arrondi √† deux d√©cimales pour cette derni√®re. Elle int√®gre une gestion d‚Äôerreurs efficace en levant une `ZeroDivisionError` en cas de division par z√©ro et une `ValueError` pour tout op√©rateur invalide, ce qui la rend robuste. Enfin, elle est accompagn√©e d‚Äôun docstring complet qui d√©crit les param√®tres, le retour, les exceptions et l‚Äôobjectif de la fonction, assurant ainsi une documentation claire et professionnelle.


‚Ä¢Prompt Sp√©cifique :
-> Les deux fonctions `calculate(a, b, op)` sont bien nomm√©es, robustes et respectent les conventions PEP8, mais la seconde version se distingue par une **meilleure structure d√©fensive**. Contrairement √† la premi√®re, qui v√©rifie les erreurs au fur et √† mesure dans chaque bloc `elif`, la seconde commence par une **v√©rification centralis√©e de la validit√© de l'op√©rateur**, ce qui permet d'arr√™ter l'ex√©cution imm√©diatement en cas d‚Äôentr√©e invalide. C√¥t√© **lisibilit√©**, les deux versions sont bien document√©es avec un docstring clair et complet, mais la deuxi√®me est l√©g√®rement plus lisible gr√¢ce √† des commentaires s√©par√©s pour chaque bloc d'op√©ration. En ce qui concerne la **couverture des cas**, les deux versions prennent en charge les quatre op√©rations math√©matiques de base avec gestion de la division par z√©ro, mais la seconde **am√©liore la clart√© logique** en pla√ßant la validation des erreurs avant l‚Äôex√©cution de toute op√©ration. En r√©sum√©, bien que les deux soient solides, la deuxi√®me version est **plus structur√©e, d√©fensive et proprement segment√©e**, ce qui la rend plus facile √† maintenir.


‚Ä¢Prompt avec Persona :
->Oui, ce code est plus professionnel car il respecte les conventions PEP8, inclut un docstring clair et d√©taill√©, et utilise des exceptions explicites pour g√©rer les erreurs comme les op√©rateurs invalides ou la division par z√©ro. Il est √©galement mieux structur√© gr√¢ce √† une validation initiale de l‚Äôop√©rateur, un encha√Ænement logique des conditions, et une organisation claire qui facilite la lecture et la maintenance. Enfin, il est plus s√©curis√© car il anticipe les erreurs critiques et limite l‚Äôex√©cution aux seuls cas pr√©vus, garantissant ainsi un comportement fiable et contr√¥l√©.

# Analyse Critique:
1) Diff√©rences entre les codes g√©n√©r√©s :

Chaque prompt a produit une version diff√©rente de la fonction calculate. Le 
premier, tr√®s vague, a donn√© un code basique, sans v√©rification des erreurs, 
sans commentaires ni explication. Le second prompt, un peu plus pr√©cis, a 
g√©n√©r√© une fonction correcte avec la gestion de la division par z√©ro, des 
op√©rateurs invalides et un arrondi pour la division, mais toujours sans 
v√©rification des types ou structure avanc√©e. Enfin, le prompt le plus 
d√©taill√©, avec des consignes claires sur la qualit√© attendue (PEP8, erreurs, 
docstring), a permis de g√©n√©rer une fonction compl√®te, professionnelle, bien 
comment√©e, et respectant les bonnes pratiques de Python. On voit donc 
clairement que plus le prompt est pr√©cis, plus la qualit√© du code est √©lev√©e.

2) Principe de prompt engineering le plus impactant :

Parmi les principes de prompt engineering (clart√©, sp√©cificit√©, persona), 
c‚Äôest la sp√©cificit√© qui a eu le plus d‚Äôimpact. En donnant des d√©tails tr√®s 
pr√©cis sur ce que la fonction devait faire (types des donn√©es, erreurs √† 
g√©rer, style PEP8, docstring, etc.), l‚ÄôIA a pu produire un code bien 
structur√©, robuste et directement r√©utilisable. Sans ces pr√©cisions, l‚ÄôIA 
reste dans une r√©ponse g√©n√©rique. La clart√© et l‚Äôutilisation d‚Äôun persona 
(ex. "en tant que d√©veloppeur Python") aident aussi, mais c‚Äôest la 
sp√©cificit√© qui change vraiment la qualit√© du r√©sultat.

3) Erreurs ou comportements inattendus :

Oui, l‚ÄôIA a introduit des lacunes dans la premi√®re version. Par exemple, 
elle ne v√©rifie pas si les entr√©es sont bien des entiers, et ne g√®re pas 
proprement les erreurs comme une division par z√©ro ou un op√©rateur invalide. 
Ces oublis peuvent provoquer des bugs ou des plantages si on utilise la 
fonction dans un vrai programme. √Ä partir du deuxi√®me prompt, ces erreurs 
sont corrig√©es car les consignes sont plus claires.

4) Co√ªt en temps et en effort : prompt vague vs. prompt sp√©cifique :

Un prompt vague demande peu d‚Äôeffort au d√©part, mais entra√Æne souvent 
beaucoup de travail ensuite pour corriger et am√©liorer le code (ajouter des 
v√©rifications, commentaires, etc.). √Ä l‚Äôinverse, un prompt sp√©cifique 
demande un peu plus de temps √† formuler, mais il permet d‚Äôobtenir un code de 
qualit√© d√®s le d√©part, ce qui fait gagner du temps au final. Donc, mieux 
vaut prendre quelques secondes de plus pour bien formuler sa demande, plut√¥t 
que corriger un code incomplet ensuite.

# Exercice 2.2 : G√©n√©ration d'une fonction en  Python  :
‚Ä¢ z√©ro-Shot Prompting:
->Oui, le code est correct et robuste. Il v√©rifie que l‚Äôentr√©e est bien une 
cha√Æne de 10 caract√®res alphanum√©riques, et l√®ve des erreurs claires si ce 
n‚Äôest pas le cas. Le format appliqu√© (`XXX-XXXX-XXX`) est respect√©, et le 
code est bien structur√© avec un docstring clair et conforme aux bonnes 
pratiques.
‚Ä¢ One-Shot Prompting :
->Oui, l‚Äôajout d‚Äôun exemple concret dans le prompt a clairement simplifi√© la 
t√¢che de l‚ÄôIA et renforc√© la pr√©cision du r√©sultat. Contrairement √† la 
version pr√©c√©dente o√π le format √©tait bas√© uniquement sur une description 
textuelle (`XXX-XXXX-XXX`), cette version utilise un exemple d‚Äôentr√©e-sortie 
explicite (`"ABC123DEF4"` ‚Üí `"ABC-123-DEF4"`), ce qui a permis √† l‚ÄôIA 
d‚Äôappliquer le bon d√©coupage (apr√®s le 3e et le 6e caract√®re). Cela √©vite 
toute ambigu√Øt√© et corrige l‚Äôerreur pr√©c√©dente o√π le format appliqu√© ne 
correspondait pas exactement √† l‚Äôintention. En r√©sum√©, l‚Äôexemple fourni a 
permis une meilleure compr√©hension et a r√©duit le risque d‚Äôerreur de format.
‚Ä¢ Few-Shot prompting :
-> Oui, l‚ÄôIA g√®re nettement mieux les cas d‚Äôerreur dans cette version. Gr√¢ce 
aux exemples positifs et n√©gatifs int√©gr√©s (cas valide et cas invalide comme 
`"SHORT"`), la fonction est plus robuste : elle v√©rifie explicitement que 
l'entr√©e est une cha√Æne, qu'elle contient exactement 10 caract√®res, et 
qu'elle est alphanum√©rique. Les messages d'erreur sont clairs et pr√©cis, ce 
qui facilite le d√©bogage et l‚Äôutilisation s√©curis√©e de la fonction. L‚Äôajout 
de plusieurs exemples dans le prompt (Few-Shot Prompting) a donc renforc√© la 
compr√©hension du format attendu et permis de traiter les erreurs de mani√®re 
compl√®te et fiable.

## Analyse Critique :
1)  Influence des exemples sur la compr√©hension de l‚ÄôIA
L‚Äôajout d‚Äôexemples, en particulier d‚Äôentr√©es-sorties pr√©cises (comme 
"ABC123DEF4" ‚Üí "ABC-123-DEF4"), am√©liore consid√©rablement la compr√©hension 
de l‚ÄôIA, surtout lorsqu‚Äôil s‚Äôagit de r√®gles complexes ou de formats 
sp√©cifiques. Les exemples agissent comme des cas concrets qui r√©duisent 
l‚Äôambigu√Øt√© du langage naturel. Cela permet √† l‚ÄôIA de mieux interpr√©ter la 
logique attendue (comme o√π ins√©rer les tirets) et de g√©n√©rer un code 
conforme √† l‚Äôintention r√©elle. En ajoutant √©galement des cas d‚Äôerreur, l‚ÄôIA 
est plus encline √† int√©grer des v√©rifications robustes (longueur, type, 
alphanum√©rique) et √† lever des exceptions appropri√©es. Ainsi, les exemples
servent √† guider le raisonnement de l‚ÄôIA et renforcent la fiabilit√© du code 
g√©n√©r√©.

2) Utilit√© du Few-Shot Prompting en d√©veloppement
Le Few-Shot Prompting est particuli√®rement utile lorsque :

‚Ä¢ La t√¢che est complexe ou sp√©cifique, avec des r√®gles m√©tiers ou de format 
non standard.

‚Ä¢ On veut √©viter les erreurs logiques dans le code g√©n√©r√©.

‚Ä¢ On cherche √† g√©n√©rer du code robuste, notamment avec une bonne gestion des 
cas limites et des erreurs.

‚Ä¢ On veut reproduire un comportement conforme √† des exemples concrets, plut√¥t qu‚Äô√† une description abstraite.

‚Ä¢ Il est aussi tr√®s efficace pour enseigner √† l‚ÄôIA le style attendu, que ce 
soit dans le formatage du code, les noms de fonctions, ou la r√©daction de 
docstring.

3) Limites des exemples (nombre, qualit√©)
-> Oui, il existe des limites :
‚Ä¢ Trop d‚Äôexemples peuvent rendre le prompt lourd, ralentir la r√©ponse de 
l‚ÄôIA ou m√™me la perturber si les exemples sont contradictoires ou mal 
choisis.

‚Ä¢ La qualit√© est essentielle : un exemple mal con√ßu (erreur de format, nom 
trompeur) peut induire l‚ÄôIA en erreur.

‚Ä¢ Si les exemples ne couvrent pas les cas d'erreur ou les exceptions, l‚ÄôIA 
risque de ne pas anticiper ces situations.

‚Ä¢ Enfin, les exemples doivent rester repr√©sentatifs de ce qu‚Äôon attend 
r√©ellement ; s‚Äôils sont trop simples, l‚ÄôIA risque de g√©n√©raliser 
incorrectement.

# Exercice 2.3 : G√©n√©ration d'un petit site web en  Python  :
1) "Cr√©e une mini-application Web qui simule une calculatrice avec HTML, CSS 
et JavaScript." 
=>Le r√©sultat du prompt vague donne une calculatrice tr√®s basique, avec une interface peu soign√©e, des boutons mal align√©s, aucun style responsive, et une logique JavaScript minimale souvent √©crite en bloc. Il n‚Äôy a pas de gestion d‚Äôerreurs, ni de s√©paration claire entre HTML, CSS et JS, ce qui rend le code difficile √† maintenir et peu adapt√© √† une utilisation s√©rieuse.

2) "Tu es un d√©veloppeur web exp√©riment√©, avec... cites au 
niveau de la consigne "

3) L‚Äô√©valuation des diff√©rentes versions de prompts montre clairement 
l‚Äôimpact de la formulation sur la qualit√© du code g√©n√©r√©. Un prompt vague, 
comme ‚ÄúCr√©e une mini-calculatrice en HTML, CSS et JS‚Äù, donne un r√©sultat 
tr√®s basique : une interface minimaliste, peu ou pas de style, et un code 
JavaScript peu structur√©, sans gestion des erreurs. Lorsque le prompt inclut 
quelques d√©tails techniques (types de boutons, affichage, style moderne, 
gestion des erreurs), la calculatrice devient plus fonctionnelle, mieux 
pr√©sent√©e, avec un d√©but de structure et une certaine logique de validation. 
En revanche, le prompt structur√© avec une persona (d√©veloppeur exp√©riment√©) 
et des contraintes pr√©cises (responsivit√©, accessibilit√©, HTML/CSS/JS pur, 
pas de framework) aboutit √† un code complet, bien organis√© et maintenable. 
L‚Äôinterface est esth√©tique, le JavaScript est clair et modulaire, et 
l‚Äôapplication est utilisable aussi bien sur ordinateur que sur mobile. En 
r√©sum√©, plus le prompt est d√©taill√© et contextualis√©, plus l‚ÄôIA g√©n√®re un 
code robuste, lisible et proche d‚Äôun r√©sultat professionnel.

## üß† Partie 3 ‚Äì D√©bogage et Am√©lioration du Code
# Exercice 3.2 :
1) Le code initial trie une liste d'entiers en ordre croissant √† l'aide d‚Äôun 
algorithme simple de type s√©lection ou bulle, mais il pr√©sente plusieurs 
d√©fauts de lisibilit√©. Il est √©crit en bloc sans fonction, avec des noms de 
variables peu explicites (a, i, j, tmp), aucun commentaire ni docstring, ne 
respecte pas la convention PEP8, et n'inclut pas de bloc conditionnel if 
__name__ == "__main__", ce qui rend sa lecture, sa maintenance et sa 
r√©utilisation difficiles.

# Exercice 3.3 : G√©n√©ration de Documentation
3) √©valuation :
‚Ä¢ Clart√© : La docstring et le README sont tr√®s lisibles.
‚Ä¢ Compl√©tude : Tous les √©l√©ments demand√©s sont pr√©sents : but, param√®tres, retour, exemple.
‚Ä¢ Facilit√© de compr√©hension : Oui, m√™me un nouveau d√©veloppeur peut comprendre l‚Äôusage de la fonction rapidement.



